{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a424b44",
   "metadata": {},
   "source": [
    "# Speech Understanding \n",
    "# Lecture 10: Fourier analysis of natural speech"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3983e7c",
   "metadata": {},
   "source": [
    "### Mark Hasegawa-Johnson, KCGI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa13a99",
   "metadata": {},
   "source": [
    "* A synthetic vowel can be analyzed by taking the Fourier transform of the whole numpy array\n",
    "* Real speech changes over time\n",
    "* In order to cope with the changes over time, we can use the short-time Fourier transform (STFT)\n",
    "* The log magnitude STFT is called the spectrogram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8ca0a6",
   "metadata": {},
   "source": [
    "Here are the contents:\n",
    "1. <a href=\"#section1\">Using ipywebrtc to record speech</a>\n",
    "1. <a href=\"#section2\">Using librosa to read speech audio files</a>\n",
    "1. <a href=\"#section3\">Calculating a spectrogram using `np.fft.fft`</a>\n",
    "1. <a href=\"#section4\">Calculating a spectrogram using librosa</a>\n",
    "1. <a href=\"#homework\">Homework</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f5b87c",
   "metadata": {},
   "source": [
    "<a id='section1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc1f1a1",
   "metadata": {},
   "source": [
    "## 1.  Using <a href=\"https://ipywebrtc.readthedocs.io/en/latest/\">ipywebrtc</a> to record speech"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c958c9dc",
   "metadata": {},
   "source": [
    "[ipywebrtc](https://ipywebrtc.readthedocs.io/en/latest/) is a general package for recording audio and video into your Jupyter notebook.\n",
    "\n",
    "In order to use ipywebrtc, first you need to install it.  You can do that using the following shell command, or by issuing the same command without the \"!\" in a terminal window:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e287d45e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywebrtc in c:\\users\\st071993\\anaconda3\\lib\\site-packages (0.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install ipywebrtc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1975c563",
   "metadata": {},
   "source": [
    "Recording audio using ipywebrtc is exactly the same as recording video, except that we create a `CameraStream` object with the constraints `'audio':True, 'video':False`.  With those constraints, the camera stream will record only audio, not video.\n",
    "\n",
    "When you the circle button is black, you can press it to start recording.  When it is red, you can press it to stop recording."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "005827bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc0e026c52164efdaa755b903272dc89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "AudioRecorder(audio=Audio(value=b'', format='webm'), stream=CameraStream(constraints={'audio': True, 'video': â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywebrtc\n",
    "camera = ipywebrtc.CameraStream(constraints={'audio': True,'video':False})\n",
    "recorder = ipywebrtc.AudioRecorder(stream=camera)\n",
    "recorder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0382982",
   "metadata": {},
   "source": [
    "If we print the `recorder` object, we can see its contents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "487e353d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AudioRecorder(audio=Audio(value=b'', format='webm'), stream=CameraStream(constraints={'audio': True, 'video': False}))\n"
     ]
    }
   ],
   "source": [
    "print(recorder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddab695",
   "metadata": {},
   "source": [
    "We can see that it is an `AudioRecorder` object, with the following member data:\n",
    "* audio - an audio object, containing\n",
    "   * value - the binary data of the recorded audio waveform\n",
    "   * format='webm' - the audio coding format in which audio.value is stored\n",
    "* stream - the `CameraStream` object from which the audio was recorded\n",
    "\n",
    "There are several ways to convert the `audio.value` data into a numpy array, but one of the simplest and most general is to just save it as a binary `.webm` file, then read it in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5835b85b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recording.webm is a file containing 0 bytes\n"
     ]
    }
   ],
   "source": [
    "with open('recording.webm','wb') as f:\n",
    "    f.write(recorder.audio.value)\n",
    "    \n",
    "import os\n",
    "print('recording.webm is a file containing',os.stat('recording.webm').st_size,'bytes')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731a115a",
   "metadata": {},
   "source": [
    "<a id='section2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f8148f",
   "metadata": {},
   "source": [
    "## 2. Using [librosa](https://librosa.org/doc/latest/generated/librosa.feature.melspectrogram.html) to read speech audio files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500c2dc3",
   "metadata": {},
   "source": [
    "[librosa](https://librosa.org/doc/latest/generated/librosa.feature.melspectrogram.html) is a very general package for synthesizing and analyzing audio files.  For now, let's use it to read in the `.webm` file you just created.  First, you need to install it.  In this line, the `-q` flag prevents pip from printing anything unless there is an error.  If nothing is printed, then you have no errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe6fdb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054c56b8",
   "metadata": {},
   "source": [
    "The [librosa.load](https://librosa.org/doc/latest/generated/librosa.load.html#librosa.load) function is able to read a wider variety of audio file formats than any other python package I know."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f30ad1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-963d87d44381>:5: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  speech, Fs = librosa.load('recording.webm',sr=16000)\n",
      "C:\\Users\\st071993\\Anaconda3\\lib\\site-packages\\librosa\\core\\audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "ename": "EOFError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mLibsndfileError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\librosa\\core\\audio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    174\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m             \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr_native\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m__soundfile_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\librosa\\core\\audio.py\u001b[0m in \u001b[0;36m__soundfile_load\u001b[1;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;31m# Otherwise, create the soundfile object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mcontext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSoundFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\soundfile.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[0;32m    657\u001b[0m                                          format, subtype, endian)\n\u001b[1;32m--> 658\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode_int\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclosefd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    659\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missuperset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'r+'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseekable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\soundfile.py\u001b[0m in \u001b[0;36m_open\u001b[1;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[0;32m   1215\u001b[0m             \u001b[0merr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_snd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msf_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1216\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mLibsndfileError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Error opening {0!r}: \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1217\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmode_int\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_snd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSFM_WRITE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mLibsndfileError\u001b[0m: Error opening 'recording.webm': Format not recognised.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-963d87d44381>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mspeech\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'recording.webm'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mspeech_time_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspeech\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mFs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\librosa\\core\\audio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    181\u001b[0m                     \u001b[1;34m\"PySoundFile failed. Trying audioread instead.\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m                 )\n\u001b[1;32m--> 183\u001b[1;33m                 \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msr_native\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m__audioread_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\decorator.py\u001b[0m in \u001b[0;36mfun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    229\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mkwsyntax\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m                 \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 231\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mcaller\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mextras\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    232\u001b[0m     \u001b[0mfun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m     \u001b[0mfun\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\librosa\\util\\decorators.py\u001b[0m in \u001b[0;36m__wrapper\u001b[1;34m(func, *args, **kwargs)\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Would be 2, but the decorator adds a level\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m         )\n\u001b[1;32m---> 59\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__wrapper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\librosa\\core\\audio.py\u001b[0m in \u001b[0;36m__audioread_load\u001b[1;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[0;32m    237\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m         \u001b[1;31m# If the input was not an audioread object, try to open it\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 239\u001b[1;33m         \u001b[0mreader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maudioread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maudio_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mreader\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0minput_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\audioread\\__init__.py\u001b[0m in \u001b[0;36maudio_open\u001b[1;34m(path, backends)\u001b[0m\n\u001b[0;32m    125\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mBackendClass\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbackends\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mBackendClass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    128\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mDecodeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\audioread\\rawread.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filename)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maifc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fh\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0maifc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m             \u001b[1;31m# Return to the beginning of the file to try the next reader.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\aifc.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(f, mode)\u001b[0m\n\u001b[0;32m    915\u001b[0m             \u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mAifc_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    918\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'w'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mAifc_write\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\aifc.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m             \u001b[1;31m# assume it is an open file object already\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 358\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minitfp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    359\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    360\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\aifc.py\u001b[0m in \u001b[0;36minitfp\u001b[1;34m(self, file)\u001b[0m\n\u001b[0;32m    312\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_soundpos\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 314\u001b[1;33m         \u001b[0mchunk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mChunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    315\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mchunk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetname\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34mb'FORM'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    316\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'file does not start with FORM id'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\chunk.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, file, align, bigendian, inclheader)\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunkname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunkname\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munpack_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstrflag\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'L'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mEOFError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "speech, Fs = librosa.load('recording.webm',sr=16000)\n",
    "speech_time_axis = np.arange(len(speech))/Fs\n",
    "\n",
    "fig = plt.figure(figsize=(14,3),layout='tight')\n",
    "subplot = fig.subplots(1,1)\n",
    "subplot.plot(speech_time_axis,speech)\n",
    "subplot.set_xlabel('Time (seconds)',fontsize=18)\n",
    "subplot.set_title('Recording sampled at %d samples/second'%(Fs),fontsize=18)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf6953a",
   "metadata": {},
   "source": [
    "<a id='section3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ea109e",
   "metadata": {},
   "source": [
    "## 3. Calculating a spectrogram using np.fft.fft"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b91f8c",
   "metadata": {},
   "source": [
    "* A Fourier transform finds out which tones are present in a sound\n",
    "* ... but speech changes over time!\n",
    "\n",
    "In order to solve this problem, we use the **short-time Fourier transform**, or STFT.  The STFT has two steps:\n",
    "\n",
    "1. Divide `speech` into overlapping frames, resulting in a matrix\n",
    "1. Take the Fourier transform of each frame to get the **STFT**\n",
    "1. The **spectrogram** is the log magnitude of the STFT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93215de8",
   "metadata": {},
   "source": [
    "### 3.1 Divide speech into overlapping frames\n",
    "\n",
    "Typically, we use frames that are about 0.025 seconds long (25 milliseconds), with a step of 0.01 seconds (10 milliseconds).\n",
    "\n",
    "There are an amazing number of different tricky ways to create overlapping frames in python; see [this page](https://stackoverflow.com/questions/2485669/consecutive-overlapping-subsets-of-array-numpy-python) for lots of methods.  The code below is intended to avoid tricky approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7885e134",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Fs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-be8df8258ef7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mframe_length\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.025\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mFs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mFs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mnum_frames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspeech\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mframe_length\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'frame_length is'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mframe_length\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'and step is'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'and num_frames is'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_frames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Fs' is not defined"
     ]
    }
   ],
   "source": [
    "frame_length = int(0.025*Fs)\n",
    "step = int(0.01*Fs)\n",
    "num_frames = int((len(speech)-frame_length)/step)\n",
    "print('frame_length is',frame_length,'and step is',step,'and num_frames is',num_frames)\n",
    "\n",
    "speech_frames = np.zeros((frame_length, num_frames))\n",
    "for frame in range(num_frames):\n",
    "    speech_frames[:,frame] = speech[frame*step:frame*step+frame_length]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb940da8",
   "metadata": {},
   "source": [
    "We can plot this as an image.  Most of the samples will be near zero, and only a few will be strongly negative or strongly positive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9cf5dcc",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'layout'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-868f358980b2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlayout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'tight'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0msubplot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msubplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspeech_frames\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maspect\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0morigin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'lower'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msubplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_xlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Frame number'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfontsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m18\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msubplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_ylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Sample number'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfontsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m18\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mfigure\u001b[1;34m(num, figsize, dpi, facecolor, edgecolor, frameon, FigureClass, clear, **kwargs)\u001b[0m\n\u001b[0;32m    685\u001b[0m             \u001b[0mdpi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m72\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 687\u001b[1;33m         figManager = new_figure_manager(num, figsize=figsize,\n\u001b[0m\u001b[0;32m    688\u001b[0m                                         \u001b[0mdpi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdpi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    689\u001b[0m                                         \u001b[0mfacecolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfacecolor\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mnew_figure_manager\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    313\u001b[0m     \u001b[1;34m\"\"\"Create a new figure manager instance.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m     \u001b[0m_warn_if_gui_out_of_main_thread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 315\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_backend_mod\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_figure_manager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\backend_bases.py\u001b[0m in \u001b[0;36mnew_figure_manager\u001b[1;34m(cls, num, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3491\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mFigure\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3492\u001b[0m         \u001b[0mfig_cls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'FigureClass'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFigure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3493\u001b[1;33m         \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfig_cls\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3494\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnew_figure_manager_given_figure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3495\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'layout'"
     ]
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(14,4),layout='tight')\n",
    "subplot = fig.subplots(1,1)\n",
    "subplot.imshow(speech_frames,aspect='auto',origin='lower')\n",
    "subplot.set_xlabel('Frame number',fontsize=18)\n",
    "subplot.set_ylabel('Sample number',fontsize=18)\n",
    "subplot.set_title('Image of speech frames, 25ms frames with a 10ms step',fontsize=24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1976ef0e",
   "metadata": {},
   "source": [
    "### 3.2 Take the FFT of each frame to get the STFT\n",
    "\n",
    "The STFT is computed by taking the FFT of each frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c5183df",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'speech_frames' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-76fdae58a740>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mspeech_stft\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfft\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspeech_frames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlayout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'tight'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msubplot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msubplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspeech_stft\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mframe_length\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maspect\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0morigin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'lower'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'speech_frames' is not defined"
     ]
    }
   ],
   "source": [
    "speech_stft = np.fft.fft(speech_frames, axis=0)\n",
    "\n",
    "fig = plt.figure(figsize=(14,4),layout='tight')\n",
    "subplot = fig.subplots(1,1)\n",
    "subplot.imshow(np.abs(speech_stft[:frame_length//2]),aspect='auto',origin='lower')\n",
    "subplot.set_xlabel('Frame number',fontsize=18)\n",
    "subplot.set_ylabel('Frequency bin',fontsize=18)\n",
    "subplot.set_title('Image of speech frames, 25ms frames with a 10ms step',fontsize=24)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66ea6c34",
   "metadata": {},
   "source": [
    "### 3.3 The spectrogram is the log magnitude STFT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6dd6ad8",
   "metadata": {},
   "source": [
    "As you can see from the plot above, the STFT is close to zero in most frequency bins.  Low-amplitude information can be made more visible by taking the logarithm.\n",
    "\n",
    "#### Standardization: Use decibels, `20*log10(abs(stft))`\n",
    "If you use `np.log` to calculate the logarithm, then your spectrogram units are not obvious.  If you use `20*np.log10`, then you can say that your spectrogram expresses levels in units of decibels.  The <a href=\"https://en.wikipedia.org/wiki/Decibel\">decibel</a> is an international standard way of expressing logarithms.  Since it's an international standard, it's nice to use it.\n",
    "\n",
    "#### Normalization: Normalize maximum to 0dB, Clip minimum to -60dB\n",
    "In order to avoid taking the logarithm of zero, it's a good idea to use `np.amax` and `np.maximum` so that the largest value is 0dB ($=20\\log_{10}(1)$), and the smallest value is -60dB ($=20\\log_{10}(0.001)$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4118e3aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'speech_stft' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-8b2089782a16>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmstft\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspeech_stft\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mspeech_spectrogram\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog10\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmstft\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mamax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmstft\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlayout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'tight'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0msubplot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'speech_stft' is not defined"
     ]
    }
   ],
   "source": [
    "mstft = np.abs(speech_stft)\n",
    "speech_spectrogram = 20*np.log10(np.maximum(0.001,mstft/np.amax(mstft)))\n",
    "                            \n",
    "fig = plt.figure(figsize=(14,4),layout='tight')\n",
    "subplot = fig.subplots(1,1)\n",
    "subplot.imshow(speech_spectrogram[:frame_length//2],aspect='auto',origin='lower')\n",
    "subplot.set_xlabel('Frame number',fontsize=18)\n",
    "subplot.set_ylabel('Frequency bin',fontsize=18)\n",
    "subplot.set_title('Image of speech frames, 25ms frames with a 10ms step',fontsize=24)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564707ab",
   "metadata": {},
   "source": [
    "<a id='section4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606aa76c",
   "metadata": {},
   "source": [
    "## 4. Calculating a spectrogram using librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecdf67d",
   "metadata": {},
   "source": [
    "librosa contains some useful functions:\n",
    "\n",
    "* <a href=\"https://librosa.org/doc/main/generated/librosa.stft.html\">librosa.stft</a> will chop a signal into frames, and find the STFT\n",
    "* <a href=\"https://librosa.org/doc/main/generated/librosa.amplitude_to_db.html\">librosa.amplitude_to_db</a> converts the magnitude to decibels\n",
    "* <a href=\"https://librosa.org/doc/main/generated/librosa.display.specshow.html#librosa.display.specshow\">librosa.display.specshow</a> has some extra settings that are useful for making useful images of spectrograms; for example, it can label the X-axis in seconds, and the Y-axis in Hertz.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "add5997c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Fs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-0b2283164067>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mstep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.01\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mFs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mframelength\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.025\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mFs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Fs' is not defined"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "\n",
    "step = int(0.01*Fs)\n",
    "framelength = int(0.025*Fs)\n",
    "\n",
    "librosa_stft = librosa.stft(speech,hop_length=step,win_length=framelength)\n",
    "librosa_spectrogram = librosa.amplitude_to_db(np.abs(librosa_stft))\n",
    "librosa.display.specshow(librosa_spectrogram,sr=Fs,hop_length=step,x_axis='s',y_axis='hz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e813bc9",
   "metadata": {},
   "source": [
    "<a id=\"homework\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6b32d4",
   "metadata": {},
   "source": [
    "## Homework "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9eeaa5",
   "metadata": {},
   "source": [
    "Homework will be graded on Github.com.  Edit the file in this directory called `homework10.py`.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5751d6e2",
   "metadata": {},
   "source": [
    "### Homework 10.1: waveform_to_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8c8138f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function waveform_to_frames in module homework10:\n",
      "\n",
      "waveform_to_frames(waveform, frame_length, step)\n",
      "    Chop a waveform into overlapping frames.\n",
      "    \n",
      "    @params:\n",
      "    waveform (np.ndarray(N)) - the waveform\n",
      "    frame_length (scalar) - length of the frame, in samples\n",
      "    step (scalar) - step size, in samples\n",
      "    \n",
      "    @returns:\n",
      "    frames (np.ndarray((frame_length, num_frames))) - waveform chopped into frames\n",
      "    \n",
      "    num_frames should be at least int((len(speech)-frame_length)/step); it may be longer.\n",
      "    For every n and t such that 0 <= t*step+n <= N-1, it should be the case that \n",
      "       frames[n,t] = waveform[t*step+n]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import importlib, homework10\n",
    "importlib.reload(homework10)\n",
    "help(homework10.waveform_to_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "779f2d5c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'speech' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-f89f28e2ceac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhomework10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mframes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhomework10\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaveform_to_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspeech\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0morigin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'lower'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maspect\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'speech' is not defined"
     ]
    }
   ],
   "source": [
    "importlib.reload(homework10)\n",
    "frames = homework10.waveform_to_frames(speech, frame_length, step)\n",
    "plt.imshow(frames,origin='lower',aspect='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf95bf4",
   "metadata": {},
   "source": [
    "### Homework 10.2: frames_to_stft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06fa71a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function frames_to_stft in module homework10:\n",
      "\n",
      "frames_to_stft(frames)\n",
      "    Take the FFT of every column of the frames matrix.\n",
      "    \n",
      "    @params:\n",
      "    frames (np.ndarray((frame_length, num_frames))) - the speech samples (real-valued)\n",
      "    \n",
      "    @returns:\n",
      "    stft (np.ndarray((frame_length,num_frames))) - the STFT (complex-valued)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(homework10)\n",
    "help(homework10.frames_to_stft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "63efbf9f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'frames' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-b83b7f09927d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhomework10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mstft\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhomework10\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframes_to_stft\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstft\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mframe_length\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0morigin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'lower'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maspect\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'frames' is not defined"
     ]
    }
   ],
   "source": [
    "importlib.reload(homework10)\n",
    "stft = homework10.frames_to_stft(frames)\n",
    "plt.imshow(np.abs(stft[:frame_length//2]),origin='lower',aspect='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb726db",
   "metadata": {},
   "source": [
    "### Homework 10.3: stft_to_spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77121659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function stft_to_spectrogram in module homework10:\n",
      "\n",
      "stft_to_spectrogram(stft)\n",
      "    Calculate the level, in decibels, of each complex-valued sample of the STFT,\n",
      "    normalized so the highest value is 0dB, \n",
      "    and clipped so that the lowest value is -60dB.\n",
      "    \n",
      "    @params:\n",
      "    stft (np.ndarray((frame_length,num_frames))) - STFT (complex-valued)\n",
      "    \n",
      "    @returns:\n",
      "    spectrogram (np.ndarray((frame_length,num_frames)) - spectrogram (real-valued)\n",
      "    \n",
      "    The spectrogram should be expressed in decibels (20*log10(abs(stft)).\n",
      "    np.amax(spectrogram) should be 0dB.\n",
      "    np.amin(spectrogram) should be no smaller than -60dB.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(homework10)\n",
    "help(homework10.stft_to_spectrogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "86b2b544",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stft' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-3681f3dbf94a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhomework10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mspectrogram\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhomework10\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstft_to_spectrogram\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstft\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspectrogram\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mframe_length\u001b[0m\u001b[1;33m//\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0morigin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'lower'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maspect\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'stft' is not defined"
     ]
    }
   ],
   "source": [
    "importlib.reload(homework10)\n",
    "spectrogram = homework10.stft_to_spectrogram(stft)\n",
    "plt.imshow(spectrogram[:frame_length//2],origin='lower',aspect='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2dbe8c",
   "metadata": {},
   "source": [
    "### Receiving your grade\n",
    "\n",
    "In order to receive a grade for your homework, you need to:\n",
    "\n",
    "1. Run the following code block on your machine.  The result may list some errors, and then in the very last line, it will show a score.  That score (between 0% and 100%) is the grade you have earned so far.  If you want to earn a higher grade, please continue editing `homework3.py`, and then run this code block again.\n",
    "1. When you are happy with your score (e.g., when it reaches 100%), choose `File` $\\Rightarrow$ `Save and Checkpoint`.  Then use `GitHub Desktop` to commit and push your changes.\n",
    "1. Make sure that the 100% shows on your github repo on github.com.  If it doesn't, you will not receive credit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98a99327",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "...\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.015s\n",
      "\n",
      "OK\n",
      "..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 successes out of 3 tests run\n",
      "Score: 100%\n",
      "3 successes out of 3 tests run\n",
      "Score: 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 3 tests in 0.020s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'grade' from 'C:\\\\Users\\\\st071993\\\\Desktop\\\\GitHub\\\\intro_speech_understanding\\\\2023_fall\\\\lec10\\\\grade.py'>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib, grade\n",
    "importlib.reload(grade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda5fdf9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
